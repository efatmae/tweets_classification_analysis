{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import string\n",
    "import re, math, collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop(str):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    lst = str.split(\" \")\n",
    "    lst = [i for i in lst if i not in stop]\n",
    "    return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_unwanted_words(str):\n",
    "    unwanted_words = [\"httpaddress\", \"usrid\", \"dd\", \"rt\", \"amp\", \"pm\", \" \", \"'s\", \"n't\", \"\\t\", '``', \"''\", \"\", \"//\", \"\\\\\", \"\\\\'s\", \"\\\\?\"]\n",
    "    lst = str.split(\" \")\n",
    "    lst = [i for i in lst if i not in unwanted_words]\n",
    "    return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toLower(str):\n",
    "    lst = str.split(\" \")\n",
    "    lst = [i.lower() for i in lst]\n",
    "    return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data_and_labels(positive_data_file, negative_data_file):\n",
    "    \"\"\"\n",
    "    Loads MR polarity african_data from files, splits the african_data into words and generates labels.\n",
    "    Returns split sentences and labels.\n",
    "    \"\"\"\n",
    "    # Load african_data from files\n",
    "    positive_examples = list(open(positive_data_file, \"r\").readlines())\n",
    "    positive_examples = [s.strip() for s in positive_examples]\n",
    "    positive_examples = [remove_stop(item) for item in positive_examples]\n",
    "    positive_examples = [toLower(item) for item in positive_examples]\n",
    "    positive_examples = [remove_unwanted_words(item) for item in positive_examples]\n",
    "    \n",
    "    positive_examples = [clean_str(sent) for sent in positive_examples]\n",
    "    for i in positive_examples:\n",
    "        if len(i.split(\" \")) < 3:\n",
    "            positive_examples.remove(i)\n",
    "    positive_examples = list(filter(None, positive_examples) )    \n",
    "    negative_examples = list(open(negative_data_file, \"r\").readlines())\n",
    "    negative_examples = [s.strip() for s in negative_examples]\n",
    "    negative_examples = [toLower(item) for item in negative_examples]\n",
    "    negative_examples = [remove_stop(item) for item in negative_examples]\n",
    "    negative_examples = [remove_unwanted_words(item) for item in negative_examples]\n",
    "    negative_examples = list(filter(None, negative_examples) )\n",
    "    negative_examples = [clean_str(sent) for sent in negative_examples]\n",
    "    for i in negative_examples:\n",
    "        if len(i.split(\" \")) < 3:\n",
    "            negative_examples.remove(i)\n",
    "    negative_examples = list(filter(None, negative_examples) )    \n",
    "    \n",
    "    # Split by words\n",
    "    x_text = positive_examples + negative_examples\n",
    "   # x_text = [clean_str(sent) for sent in x_text]\n",
    "    # Generate labels\n",
    "    positive_labels = [[0, 1] for _ in positive_examples]\n",
    "    negative_labels = [[1, 0] for _ in negative_examples]\n",
    "    y = np.concatenate([positive_labels, negative_labels], 0)\n",
    "\n",
    "    return positive_examples, negative_examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generat_word_dist(filename):\n",
    "    \n",
    "    unwanted_words = [\"'s\",\" \",\"n't\",\"\\t\", '``', \"''\", \"\", \"//\", \"\\\\\", \"\\\\'s\", \"\\\\?\",\"httpaddress\", \"usrid\", \"dd\", \"rt\", \"amp\", \"pm\", \" \", \"'s\", \"n't\", \"\\t\", '``', \"''\", \"\", \"//\", \"\\\\\", \"\\\\'s\", \"\\\\?\"]\n",
    "    \n",
    "    default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    fp = codecs.open(filename, 'r', 'utf-8',errors='ignore')\n",
    "    \n",
    "    words = nltk.word_tokenize(fp.read())\n",
    "    \n",
    "    # Remove single-character tokens (mostly punctuation)\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "\n",
    "    # Remove numbers\n",
    "    words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Stemming words seems to make matters worse, disabled\n",
    "    # stemmer = nltk.stem.snowball.SnowballStemmer('german')\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in default_stopwords]\n",
    "    \n",
    "    words = [clean_str(word) for word in words]\n",
    "    \n",
    "    words = [word for word in words if word not in unwanted_words]\n",
    "    \n",
    "    print(len(words))    \n",
    "    # Calculate frequency distribution\n",
    "    fdist = nltk.FreqDist(words)\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generat_word_dist_bigrams(filename):\n",
    "    \n",
    "    default_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    \n",
    "    fp = codecs.open(filename, 'r', 'utf-8',errors='ignore')\n",
    "\n",
    "    words = nltk.word_tokenize(fp.read())\n",
    "\n",
    "    # Remove single-character tokens (mostly punctuation)\n",
    "    words = [word for word in words if len(word) > 1]\n",
    "\n",
    "    # Remove numbers\n",
    "    words = [word for word in words if not word.isnumeric()]\n",
    "\n",
    "    # Lowercase all words (default_stopwords are lowercase too)\n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    # Stemming words seems to make matters worse, disabled\n",
    "    # stemmer = nltk.stem.snowball.SnowballStemmer('german')\n",
    "    # words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in default_stopwords]\n",
    "    \n",
    "    words = [clean_str(word) for word in words]\n",
    "    \n",
    "    words = nltk.bigrams(words)\n",
    "\n",
    "    # Calculate frequency distribution\n",
    "    fdist = nltk.FreqDist(words)\n",
    "    return fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_word_list(freq_dist):\n",
    "    word_lst = []\n",
    "    for word, frequency in freq_dist.most_common(1000):\n",
    "            word_lst.append(word)\n",
    "    return word_lst   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PV_pos = 'Data/PV_Data/pos_vio_news.txt'\n",
    "PV_neg = 'Data/PV_Data/neg_vio_news.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "372578\n",
      "244662\n"
     ]
    }
   ],
   "source": [
    "pos_wrd_dist_doc = generat_word_dist(PV_pos)\n",
    "neg_wrd_dist_doc = generat_word_dist(PV_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_most_occr_words = print_word_list(pos_wrd_dist_doc)\n",
    "neg_most_occr_words = print_word_list(neg_wrd_dist_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['quotidien', '01 02 2010', 'sid 15059', 'o3 as', 'afmadow middle', 'juba 20100201 500', 'morur', 'portugeuse', \"'libya\", 'wershefana', 'exchangse', \"and libya 's western\", 'ceel saliini', 'boudhima', 'zajiri', 'thor al abiyat', 'thomor', 'induction', 'christiana', 'dagadu', 'sanniqueilie', 'nov 5', 'kalenda', 'giriama', 'kipini', 'commissioned', 'ghanbatt', 'ghana armed', 'ghana for', 'cefups', 'government allied', 'ruyterwacht', 'premeditated', 'titi laoye', 'tomori', 'satisfied', 'galgduud', 'kaba kudukade', 'assuring', 'mirair', 'bungatira', 'rebs', 'reb', 'r55', 'yaqberiweyne', 'labagale', 'membres', 'senhuile sen thanol', 'agro industrial', 'fanaye', 'colusion', 'group attacked a', 'al hayy', 'nunu', 'gambella', 'shataya', 'attampted', 'transparency no', 'mandevu', 'ayr habar', 'saleban habar', 'balli howd', 'control clashes which', 'al khusus', 'armed clashes left', '01 05 2011', 'assertion', 'zewaid', 'sure', 'ajipowo', 'sisfm', 'sempana', 'gems for guns', 'ncs', 'seme', 'huffpost', 'maghagha', '15 11 98', 'nombe', 'impregnating', 'sigaale', 'ali saleban', 'ngaar saleban', 'dame', 'abdiweli', 'staircase', 'ajase ipo', 'irepodun', 'azharite', 'grandee', 'alleit', 'neby', 'kyavikere', 'palace retrieved', 'hadhwanaagnews com', 'hargeisa somaliland 20100604 1343', 'hotspots', 'vigiliante', 'moya', 'hawiye udeejeen', 'worker rights', 'artist', 'zwelethu', 'mthethwa', 'kibiya', 'hecatres', 'emure ekiti', 'propsed', 'povisions', 'mathieu', 'k r kou', 'kiangage', 'mechants', 'haffouz', 'leir', 'tam', 'maikatako', 'insubordination', 'denominations', 'el mejlissis', 'daech', 'oppoosition', 'limete', 'lror', \"sha'ban\", 'hadiyah', 'beriane', 'pin', 'corymble', 'reels', 'depository', 'jigjia', 'mauritania mali', 'hassissidi', 'chisumbanje', 'ethanol', 'portfolio', 'konguia', 'fochville', 'directs', 'registry', 'al manar', 'tumbuktu', 'phosphorous', 'cellou', 'dalein', 'houseboat', 'awad', \"morocco 's progress\", 'oudtshoorn', 'abugi', 'bounce', 'mid week', 'twenties', 'fool', 'feyle', 'shabba', 'amass', 'camouflage', 'kangunzi', 'pienaar', 'luanshya', 'hijer', 'madsees', 'kahenzi', 'ozowa', 'yaqin', 'jwamda kobla', 'murzuk', 'saturday s attacks on', 'soviet', 'bilibokree', 'juarzon', 'd s', 'adegbenro', 'ict', 'ewekoro', 'lagos abeokuta', 'wala', 'sharow', 'acho', 'gozmena', 'rufa', 'kokari', 'mugger', 'mashou', 'g d on', 'kibawa', 'rolling', 'pre paid', 'station prison', 'acttacked', 'kyombogo', 'te', 'abed', 'town yesterday in', 'claims the', 'bayturaas', 'state certified', 'inuwa', 'kubo', 'klipheuwel', 'pochalla', 'preferential', 'ikeinghenbiri', 'collins', 'adikoko', 'rulimba', 'airstrip area', 'lyanza lac', 'nsongo', 'mboyoin', 'contaminated', 'retirees', 'matambanadzo', 'kushinga', 'marco', 'msipa', 'into the', 'dhiridmaadle', 'bacaroor', 'malembe', 'assa', 'vyrheid', 'matot', 'pulchuol', 'guancot', 'rumaker', 'dorganwel', 'tongyang', 'sherikat', 'cabdulcasiis', 'vigorously', 'fatayah', 'pillars', 'shahat', 'graffiti', 'idols', 'worships', 'benchoud', 'meeing', 'natonal', 'evolved', 'hindering', 'discovers', 'al fataih', 'nahaj', 'local libya dawn', 'transnamib', 'drc uganda', 'in egypt to protest against', 'unwarranted', 'navigation', 'cnan group', 'protestation', 'devant', 'si ge', 'leur', 'g n rale', 'early month', 'hulugho', 'baaqey', 'djarras', 'reconciled', 'ganga', 'ijag', 'desopadec', 'agulu', 'fauri', 'judicially', 'victimized', 'publicity', 'attmepts', 'loma', 'widows orphans', '19 08 2000', 'forsan', 'west on', 'rijban', 'vigils', 'nyankanda', 'low level', 'dailies', '16t', 'reputed', 'mental', '5 5', 'bruised', 'cairo s', 'zeinhom', 'dissemenating', 'yaaq biri weyne', 'makwaj', 'gorlu', 'ganglota', 'salayae', 'fdlr rude', 'imposing', 'deeply', 'verifying', 'sugoi', 'fabrication', 'matali', 'beletweyn', 'galshire', 'snp', 'majak koot', 'traffciking', 'blukwa', 'mbi', 'melilia', 'al sadiq', 'mechanic', 'repairing', 'camel back', 'oteri', 'thoroughly', 'masaba', 'subsidise', 'relieve', 'shinile', 'dolo', 'jerer', 'hore', \"gara'ad\", 'lahreche', 'baasare', 'chinese owned', 'ugcaa', 'kitkit', 'initiates', '06 06 2003', 'willingly', 'recovere', 'equatoguinean', 'voie', 'sonabel', 'auguste', 'ouedraogo', 'goodwood', 'awaiting trial', 'cederberg', 'co ordinated', 'bamba', 'eisleben', 'photographer s', 'school s', 'corridors', 'dji0000020080208e428000r4', 'alngamba', 'dashab', 'tammah', \"'agressors\", 'bassankusu', 'sath', 'ndam', 'lamin', 'waa', 'juwara', 'unsound', 'muhani', 'pro ravalomanana', 'bedji', 'coexistence', 'hawlwadaag', 'thembelihle', 'kakor', 'walaalaha', 'rust', 'ter', 'val', 'mangasaba', 'ugandan back', 'jildu', 'ghardimaou', 'nyamyumba', 'shegega', 'overturn', 'suspensions expulsion', 'vicious', 'baytaruus', '07 09 2015', 'anti iraq', 'countries in', 'urbanism', 'kiambuthi', '965', '1000 km', 'hamarweyn', 'referring', 'fronabu tabara', 'casualtie', 'pours', 'slashing', 'n500 , 000', 'n100 , 000', 'wagosha', 'zouhair', 'yahyaoui', 'abm', \"n'gourma\", 'gadam', 'dumma', 'conferences', 'ipu', 'rahaweyne malim', 'contacting', 'happens', 'ledig', 'bisellia', 'bringi', 'rover', 'war isse', 'clashes intensified', 'cadey', 'bakwanga', 'kanyaru', '5 6', 'berkeda', 'sharifada', 'turquta', 'cabdiwayeel', 'snfpf', 'majeerten umar', 'two sub', 'limiting', 'half way', 'warshad', 'galey', 'modderspruit', 'makutano alale', 'ngoubo', 'vastrap', 'ounif', 'bechar', 'run up', 'al zuway', 'al nasij', 'pepa', 'banama', 'medina dharkenley', 'constiuency', 'rew', 'relics', 'boor', 'manyiel', 'essakane', 'homemade bomb', 'lalogi', 'zarda', 'brief protest in', 'shukri', 'al qutali', 'al mahalah', 'their protest', 'motlanthe', 'amisom pro sng', 'lagta', 'berta', 'ami', 'drankola', 'hujub', '22 01 2010', 'www hiiraan com news 2010 jan wararka maanta21 8681 htm', 'o3 aswj', 'hujub baardheere', '20100122 435', 'demobilisation', 'army raid near', 'discrepancies', 'motor cycles', 'rdl janjaweed', 'redjaem', 'nasiye', '86km', 'abduct kill', 'sopo', 'take away', 'eaf', 'maitikoulou', 'markounda', 'beboura', 'choice', 'ski', 'whales', 'activates', 'illorin', 'infamous', 'mazimbele', 'pertains', 'qurans', 'guantanamo', 'eral', 'tshuma', 'el labban', 'qoranic', 'waridme', 'belet weyne', 'bulo burte', 'durable', 'hamper', 'dirt', 'galjeel', 'freely', 'yapta', 'kortumbak', 'ngarangba', 'makurdi gbajimba', 'oprative', 'ejembi', 'ogwuche', 'pursues', 'abdiwayel', 'caregivers', 'volunteering', 'klarinet', 'bused', 'meftah', 'al sabaa', '05 10 the', 'acute', 'kibungu', 'qansah dheere', 'bukirasazi', 'zogota', \"n'zerekore\", 'brazilian', 'victorious', 'nebeur', 'scourge', 'kibeleketa', '72 year old', 'dhlakam', 'mamb r', 'kad', 'nana gr bizi', 'nana mamb r', 'sangha mba r', 'soetwater', 'riig', 'kam', 'waregley', 'napere', 'groblersdal', 'karaba', 'mbeere', 'nyakarhalaga', 'gbb fr', 'alexandre', 'tladi', 'kamoli', 'arsenal', 'makindu', 'mengu', 'stawu', 'hamash', 'koreb', 'plotted', 'grid', 'haradle', \"'rebels\", 'sedhiou', 'lingering', 'collateral', 'madote', 'gourma', 'housewife', 'al kushah', 'anti riot police', 'lifetime', 'abu hammad', 'pikine', 'worst clashes they', 'hf', 'jonathan s', 'addresses', 'topics', 'dufan', 'onlf a', 'ar', 'jijiga degeh', 'anti jihadist', 'c 100', '53rd', 'mwesso', 'saddam', 'airforce', 'pro independence', 'gardhub', 'jra', 'inter communal', 'marial lou', 'mminova', 'kahele', 'siera', 'ad hoc', 'underpayment', 'ambo', 'kigarigari', 'regifi', \"county'\", 'tirab', 'busitema', 'muni', 'non teaching', 'al jara', 'qait', 'divides', 'chases', 'kigomagoma', 'simbas', 'el mahalla', 'el koubra', 'dungu garamba', 'mlpc', 'ethinc', 'abdinur', 'kaba kutukade', 'berberti', 'boa', 'gueli', 'banbari', 'bangato', 'supervise', 'azare', 'keiyo', 'ex dictator', 'zine', 'abidine', 'post savimbi', 'cpa', 'jun 10', 'smc', 'abd al rahman', 'al rida', 'the attack by', 'amran', 'shamah', 'jagjag', 'bbcmep0020080626e46q0038p', 'langi', 'iteso', 'kumam', 'two page', 'bembe', 'mandro', 'airports', 'qoryole', '02 03 2003', 'fianc', 'bakht', 'alrida', 'baga monguno', 'tungushe', 'dogonwaya', 'songolo', 'embezzlement', 'suweyto', 'exported', 'respecting', 'relationships', 'jasaayir', 'of clashes betwen', 'hanoville', '30 12 00', 'mistaking', 'debba', 'fernana', 'lebenga', 'belfast', 'sutcliffe', '16 day', 'involed', 'genocied', 'anti rape', 'sidi anssa', 'kiwanjani', 'keita', 'soumaila', 'ghennif', 'touzaline', 'beldgo', 'dindaro', 'bodhei', 'depth', 'yora', 'mareehan wagardhac', 'ongoing clashes', 'reported between', 'post electoral']\n"
     ]
    }
   ],
   "source": [
    "print(pos_most_occr_words[30000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market 9066   -   market 344\n",
      "new 2113   -   new 305\n",
      "report 1619   -   report 231\n",
      "health 3716   -   health 95\n",
      "business 5662   -   business 73\n",
      "tv 1200   -   tv 32\n",
      "technology 4473   -   technology 28\n",
      "finance 1254   -   finance 20\n",
      "research 4608   -   research 12\n",
      "announces 1311   -   announces 9\n",
      "markets 4137   -   markets 7\n",
      "global 2063   -   global 7\n",
      "12\n",
      "market,new,report,health,business,tv,technology,finance,research,announces,markets,global\n"
     ]
    }
   ],
   "source": [
    "# the no. occurances of the most freq words in pos in the negative set\n",
    "l = []\n",
    "c=0\n",
    "for i in pos_most_occr_words:\n",
    "    if neg_wrd_dist_doc[i] > 1000:\n",
    "        c +=1\n",
    "        l.append(i)\n",
    "        print(i, neg_wrd_dist_doc[i],'  -  ', i,pos_wrd_dist_doc[i])\n",
    "print(c)\n",
    "print(\",\".join(l))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group 2011   -   group 732\n",
      "security 1474   -   security 187\n",
      "state 1074   -   state 167\n",
      "one 1710   -   one 166\n",
      "two 3095   -   two 113\n",
      "government 1938   -   government 98\n",
      "local 1001   -   local 88\n",
      "three 1355   -   three 69\n",
      "area 1819   -   area 68\n",
      "students 1012   -   students 53\n",
      "members 1279   -   members 49\n",
      "military 1553   -   military 43\n",
      "forces 3960   -   forces 39\n",
      "people 2082   -   people 36\n",
      "near 1322   -   near 25\n",
      "district 1450   -   district 24\n",
      "reported 1665   -   reported 21\n",
      "police 4061   -   police 19\n",
      "al 1828   -   al 12\n",
      "attack 2866   -   attack 12\n",
      "army 1071   -   army 12\n",
      "town 1369   -   town 9\n",
      "shot 1369   -   shot 8\n",
      "fighting 1077   -   fighting 8\n",
      "village 1577   -   village 6\n",
      "protest 2353   -   protest 3\n",
      "attacked 1838   -   attacked 3\n",
      "injured 1976   -   injured 2\n",
      "killed 5322   -   killed 2\n",
      "armed 1729   -   armed 2\n",
      "rebels 1893   -   rebels 2\n",
      "soldiers 1813   -   soldiers 2\n",
      "protesters 1008   -   protesters 1\n",
      "killing 1011   -   killing 1\n",
      "unknown 1117   -   unknown 1\n",
      "suspected 1034   -   suspected 1\n",
      "36\n",
      "group,security,state,one,two,government,local,three,area,students,members,military,forces,people,near,district,reported,police,al,attack,army,town,shot,fighting,village,protest,attacked,injured,killed,armed,rebels,soldiers,protesters,killing,unknown,suspected\n"
     ]
    }
   ],
   "source": [
    "# the no. occurances of the most freq words in neg in the positive set\n",
    "c = 0\n",
    "l = []\n",
    "for i in neg_most_occr_words:\n",
    "    if pos_wrd_dist_doc[i] > 1000:\n",
    "        c+= 1\n",
    "        l.append(i)\n",
    "        print(i, pos_wrd_dist_doc[i],'  -  ', i,neg_wrd_dist_doc[i])\n",
    "print(c)\n",
    "print(\",\".join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "market 9066\n",
      "business 5662\n",
      "research 4608\n",
      "technology 4473\n",
      "markets 4137\n",
      "health 3716\n",
      "new 2113\n",
      "global 2063\n",
      "report 1619\n",
      "announces 1311\n",
      "update 1292\n",
      "finance 1254\n",
      "tv 1200\n",
      "13\n",
      "market,business,research,technology,markets,health,new,global,report,announces,update,finance,tv\n"
     ]
    }
   ],
   "source": [
    "# the no. occurances of the most freq words in neg in the positive set\n",
    "c = 0\n",
    "l = []\n",
    "for i in neg_most_occr_words:\n",
    "    if neg_wrd_dist_doc[i] > 1000:\n",
    "        c+= 1\n",
    "        l.append(i)\n",
    "        print(i, neg_wrd_dist_doc[i])\n",
    "print(c)\n",
    "print(\",\".join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_big_dist_doc = generat_word_dist_bigrams(PV_pos)\n",
    "neg_big_dist_doc = generat_word_dist_bigrams(PV_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_most_occr_bigrams = print_word_list(pos_big_dist_doc)\n",
    "neg_most_occr_bigrams = print_word_list(neg_big_dist_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('vice', 'president') 188\n",
      "('health', 'care') 602\n",
      "('new', 'york') 161\n",
      "('finance', 'minister') 154\n",
      "('small', 'business') 410\n"
     ]
    }
   ],
   "source": [
    "# the no. occurances of the most freq words in pos in the negative set\n",
    "for i in pos_most_occr_bigrams:\n",
    "    if neg_big_dist_doc[i] > 100:\n",
    "        print(i, neg_big_dist_doc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('service', 'delivery') 119\n",
      "('security', 'forces') 683\n",
      "('reports', 'indicate') 422\n",
      "('government', 'military') 115\n"
     ]
    }
   ],
   "source": [
    "# the no. occurances of the most freq words in neg in the positive set\n",
    "for i in neg_most_occr_bigrams:\n",
    "    if pos_big_dist_doc[i] > 100:\n",
    "        print(i, pos_big_dist_doc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CF_tweets_PV_pos = 'Data/turkish_protest_test_pos_prccd2.txt'\n",
    "CF_tweets_PV_neg = 'Data/turkish_protest_test_neg_prccd2.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n",
      "3386\n"
     ]
    }
   ],
   "source": [
    "CFT_pos_wrd_dist_doc = generat_word_dist(CF_tweets_PV_pos)\n",
    "CFT_neg_wrd_dist_doc = generat_word_dist(CF_tweets_PV_neg)\n",
    "CFT_pos_most_occr_words = print_word_list(CFT_pos_wrd_dist_doc)\n",
    "CFT_neg_most_occr_words = print_word_list(CFT_neg_wrd_dist_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "police 27    -   police 31\n",
      "occupygezi 90    -   occupygezi 23\n",
      "istanbul 65    -   istanbul 16\n",
      "taksim 53    -   taksim 14\n",
      "turkey 192    -   turkey 12\n",
      "gezi 25    -   gezi 12\n",
      "park 24    -   park 11\n",
      "people 44    -   people 10\n",
      "protesters 18    -   protesters 9\n",
      "turkish 47    -   turkish 9\n",
      "square 16    -   square 6\n",
      "gas 12    -   gas 6\n",
      "direngeziparki 27    -   direngeziparki 6\n",
      "via 19    -   via 5\n",
      "protests 30    -   protests 5\n",
      "erdogan 46    -   erdogan 3\n",
      "please 13    -   please 2\n",
      "says 12    -   says 1\n",
      "new 13    -   new 1\n",
      "19\n",
      "police,occupygezi,istanbul,taksim,turkey,gezi,park,people,protesters,turkish,square,gas,direngeziparki,via,protests,erdogan,please,says,new\n"
     ]
    }
   ],
   "source": [
    "# the no. occurances of the most freq words in pos in the negative set\n",
    "l = []\n",
    "c = 0\n",
    "for i in CFT_pos_most_occr_words:\n",
    "    if CFT_neg_wrd_dist_doc[i] > 10:\n",
    "        c +=1\n",
    "        l.append(i)\n",
    "        print(i, CFT_neg_wrd_dist_doc[i], '   -  ',i, CFT_pos_wrd_dist_doc[i])\n",
    "print(c)        \n",
    "print(\",\".join(l)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turkey 12    -   turkey 192\n",
      "occupygezi 23    -   occupygezi 90\n",
      "istanbul 16    -   istanbul 65\n",
      "taksim 14    -   taksim 53\n",
      "police 31    -   police 27\n",
      "gezi 12    -   gezi 25\n",
      "park 11    -   park 24\n",
      "7\n",
      "turkey,occupygezi,istanbul,taksim,police,gezi,park\n"
     ]
    }
   ],
   "source": [
    "# the no. occurances of the most freq words in neg in the positive set\n",
    "c = 0\n",
    "l = []\n",
    "for i in CFT_neg_most_occr_words:\n",
    "    if CFT_pos_wrd_dist_doc[i] > 10:\n",
    "        c+= 1\n",
    "        print(i, CFT_pos_wrd_dist_doc[i], '   -  ',i, CFT_neg_wrd_dist_doc[i])\n",
    "        l.append(i)\n",
    "print(c)        \n",
    "print(\",\".join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive 2\n",
      "negative 3\n"
     ]
    }
   ],
   "source": [
    "print('positive',CFT_pos_wrd_dist_doc['clashes'])\n",
    "print('negative',CFT_neg_wrd_dist_doc['clashes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
